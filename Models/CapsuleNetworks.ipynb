{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-08T22:14:37.602872Z",
     "start_time": "2024-07-08T22:14:35.703390Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T22:16:15.987496Z",
     "start_time": "2024-07-08T22:16:15.981812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Squash(nn.Module):\n",
    "    def __init__(self,epsilon = 1e-8):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def forward(self,s):\n",
    "        s2 = (s**2).sum(dim=-1,keepdims=True)\n",
    "        return (s2/(1+s2))*(s/torch.sqrt(s2+self.epsilon))"
   ],
   "id": "2be1d31cd3350acc",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T22:21:01.863110Z",
     "start_time": "2024-07-08T22:21:01.857023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Router(nn.Module):\n",
    "    def __init__(self,in_caps,out_caps,in_d,out_d,iterations):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_caps = in_caps\n",
    "        self.out_caps = out_caps\n",
    "        self.iterations = iterations\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.squash = Squash()\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.randn(in_caps,out_caps,in_d,out_d),requires_grad=True)\n",
    "        \n",
    "    def forward(self,u):\n",
    "        u_hat = torch.einsum('ijnm,bin->bijm',self.weight,u)\n",
    "        b = u.new_zeros(u.shape[0],self.in_caps,self.out_caps)\n",
    "        v = None\n",
    "        \n",
    "        for i in range(self.iterations):\n",
    "            c = self.softmax(b)\n",
    "            s = torch.einsum('bij,bijm->bjm',c,u_hat)\n",
    "            v = self.squash(s)\n",
    "            a = torch.einsum('bjm,bijm->bij',v,u_hat)\n",
    "            b = b+a\n",
    "        \n",
    "        return v"
   ],
   "id": "79438d60f35128d4",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T22:23:58.242648Z",
     "start_time": "2024-07-08T22:23:58.236766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MarginLoss(nn.Module):\n",
    "    def __init__(self,*,n_labels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.m_poz = 0.9\n",
    "        self.m_neg = 0.1\n",
    "        self.lambda_ =0.5\n",
    "        self.n_labels = n_labels\n",
    "        \n",
    "    def forward(self,v,labels):\n",
    "        v_norm = torch.sqrt((v**2).sum(dim=-1))\n",
    "        loss = labels * F.relu(self.m_poz - v_norm) + self.lambda_*(1.0-labels)*F.relu(v_norm - self.m_neg)\n",
    "        \n",
    "        return loss.sum(dim=-1).mean()  "
   ],
   "id": "ad58b14d9a2c61bc",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T22:32:10.619162Z",
     "start_time": "2024-07-08T22:32:10.611563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MNISTCapsuleNetworkModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1,out_channels=256,kernel_size=9,stride=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=256,out_channels=32*8,kernel_size=9,stride=2,padding=0)\n",
    "        self.squash = Squash()\n",
    "        \n",
    "        self.digit_capsules = Router(32*6*6,10,8,16,3)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(16*10,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024,784),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv1(x)) # [bs,256,20,20]\n",
    "        x = self.conv2(x) # [bs ,32*8,6 6]\n",
    "        \n",
    "        caps = x.view(x.shape[0],8,32*6*6).permute(0,2,1)\n",
    "        caps = self.squash(caps)\n",
    "        caps = self.digit_capsules(caps)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred = (caps **2).sum(-1).argmax(-1)\n",
    "            mask = torch.eye(10,device=x.device)[pred]\n",
    "            \n",
    "        reconstructions = self.decoder((caps*mask[:,:,None]).view(x.shape[0],-1))\n",
    "        reconstructions = reconstructions.view(-1,1,28,28)\n",
    "        \n",
    "        return caps,reconstructions,pred"
   ],
   "id": "b6d1b61f447a191c",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5a303745790453e0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
