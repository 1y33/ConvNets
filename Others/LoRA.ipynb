{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-10T11:29:13.597865Z",
     "start_time": "2024-07-10T11:29:13.542506Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import  tqdm\n",
    "\n",
    "_ = torch.manual_seed(0)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T11:32:08.375900Z",
     "start_time": "2024-07-10T11:31:59.781069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,),(0.3081,))\n",
    "])\n",
    "\n",
    "train_ds = datasets.MNIST(root='./data',train=False,download=True,transform=transform)\n",
    "\n",
    "test_ds = datasets.MNIST(root='./data',train=False,download=True,transform=transform)\n",
    "\n",
    "train_dl =torch.utils.data.DataLoader(train_ds,batch_size=10,shuffle=True)\n",
    "test_dl = torch.utils.data.DataLoader(test_ds,batch_size=10,shuffle=True)"
   ],
   "id": "8aadadcf54268d53",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:01<00:00, 6363927.66it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 258659.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 2285834.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T11:32:44.013664Z",
     "start_time": "2024-07-10T11:32:44.008373Z"
    }
   },
   "cell_type": "code",
   "source": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")",
   "id": "f930525319a31d2e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T11:52:39.560313Z",
     "start_time": "2024-07-10T11:52:39.538053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,hidden_size_1 = 1000,hidden_size_2=2000):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(28*28,hidden_size_1)\n",
    "        self.linear2 = nn.Linear(hidden_size_1,hidden_size_2)\n",
    "        self.linear3 = nn.Linear(hidden_size_2,10)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = x.view(-1,28*28)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "    \n",
    "net = Net().to(device)"
   ],
   "id": "8922ddc3181d5cba",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T11:53:41.292783Z",
     "start_time": "2024-07-10T11:52:40.714589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(train_loader,net,epochs=5,total_iteration_limit=None):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(),lr=0.01)\n",
    "    \n",
    "    total_iterations = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        \n",
    "        loss_sum = 0\n",
    "        num_iterations = 0\n",
    "        \n",
    "        data_iterator = tqdm(train_loader,desc=f'Epoch {epoch+1}')\n",
    "        if total_iteration_limit is not None:\n",
    "            data_iterator.total = total_iteration_limit\n",
    "        \n",
    "        for data in data_iterator:\n",
    "            num_iterations +=1\n",
    "            total_iterations +=1\n",
    "            \n",
    "            x,y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            preds = net(x.view(-1,28*28))\n",
    "            loss = loss_fn(preds,y)\n",
    "            loss_sum += loss.item()\n",
    "            avg_loss = loss_sum/num_iterations\n",
    "            data_iterator.set_postfix(loss=avg_loss)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if total_iteration_limit is not None and total_iterations >= total_iteration_limit:\n",
    "                return\n",
    "            \n",
    "train(train_dl,net,epochs=1)"
   ],
   "id": "347709bd8cf18817",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1000/1000 [01:00<00:00, 16.51it/s, loss=1.02]\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T11:53:44.952078Z",
     "start_time": "2024-07-10T11:53:44.939802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "original_weights = {}\n",
    "for name,param in net.named_parameters():\n",
    "    original_weights[name] = param.clone().detach()"
   ],
   "id": "46bc8d0aeeec616a",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T11:53:50.954270Z",
     "start_time": "2024-07-10T11:53:45.530640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    wrong_counts = [0 for i in range(10)]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_dl,desc='Testing'):\n",
    "            x ,y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = net(x.view(-1,28*28))\n",
    "            \n",
    "            # (batch,predictions)\n",
    "            for idx,i in enumerate(pred):\n",
    "                if torch.argmax(i) == y[idx]:\n",
    "                    correct+=1\n",
    "                else:\n",
    "                    wrong_counts[y[idx]] +=1\n",
    "                total+=1\n",
    "                \n",
    "    print(f\"Accuracy : {round(correct/total,3)}\")\n",
    "    for i in range(len(wrong_counts)):\n",
    "        print(f\"wrong counts for the digit {i} : {wrong_counts[i]}\")\n",
    "        \n",
    "test()"
   ],
   "id": "3fc1bfbe85cf5830",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 1000/1000 [00:05<00:00, 184.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.851\n",
      "wrong counts for the digit 0 : 214\n",
      "wrong counts for the digit 1 : 22\n",
      "wrong counts for the digit 2 : 160\n",
      "wrong counts for the digit 3 : 151\n",
      "wrong counts for the digit 4 : 213\n",
      "wrong counts for the digit 5 : 153\n",
      "wrong counts for the digit 6 : 151\n",
      "wrong counts for the digit 7 : 76\n",
      "wrong counts for the digit 8 : 93\n",
      "wrong counts for the digit 9 : 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T11:56:11.598461Z",
     "start_time": "2024-07-10T11:56:11.592549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "total_parameters_original = 0\n",
    "\n",
    "for index,layer in enumerate([net.linear1,net.linear2,net.linear3]):\n",
    "    total_parameters_original += layer.weight.nelement() + layer.bias.nelement()\n",
    "    print(f\"Layer : {index+1}, W: {layer.weight.shape} + B : {layer.bias.shape}\")\n",
    "print(f\"Total nr of params : {total_parameters_original:,}\")"
   ],
   "id": "5bd1ae63c55726a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer : 1, W: torch.Size([1000, 784]) + B : torch.Size([1000])\n",
      "Layer : 2, W: torch.Size([2000, 1000]) + B : torch.Size([2000])\n",
      "Layer : 3, W: torch.Size([10, 2000]) + B : torch.Size([10])\n",
      "Total nr of params : 2,807,010\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:08:42.392228Z",
     "start_time": "2024-07-10T12:08:42.386531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LoRAParametriaztion(nn.Module):\n",
    "    def __init__(self,in_f,out_f,rank=1,alpha=1,device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lora_A = nn.Parameter(torch.zeros((rank,out_f)).to(device))\n",
    "        self.lora_B = nn.Parameter(torch.zeros((in_f,rank)).to(device))\n",
    "        nn.init.normal_(self.lora_A,mean=0,std=1)\n",
    "        \n",
    "        self.scale = alpha/rank\n",
    "        self.enabled = True\n",
    "        \n",
    "    def forward(self,original_weights):\n",
    "        if self.enabled:\n",
    "            # X + (B*A)*scale\n",
    "            return original_weights + torch.matmul(self.lora_B,self.lora_A).view(original_weights.shape) * self.scale\n",
    "        else:\n",
    "            return original_weights\n"
   ],
   "id": "55b1d530537c2416",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:18:07.155563Z",
     "start_time": "2024-07-10T12:18:07.132084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn.utils.parametrize as parametrize\n",
    "\n",
    "def linear_layer_parameterization(layer,device,rank=1,lora_alpha=1):\n",
    "    \n",
    "    features_in,features_out = layer.weight.shape\n",
    "    \n",
    "    return LoRAParametriaztion(\n",
    "        features_in,features_out,rank=rank,alpha=lora_alpha,device=device\n",
    "    )\n",
    "\n",
    "parametrize.register_parametrization(\n",
    "        net.linear1,\"weight\",linear_layer_parameterization(net.linear1,device)\n",
    ")\n",
    "\n",
    "parametrize.register_parametrization(\n",
    "    net.linear2,\"weight\",linear_layer_parameterization(net.linear2,device)\n",
    ")\n",
    "\n",
    "parametrize.register_parametrization(\n",
    "    net.linear3,\"weight\",linear_layer_parameterization(net.linear3,device)\n",
    ")\n",
    "\n",
    "def enable_disable_lore(enabled=True):\n",
    "    for layer in [net.linear1,net.linear2,net.linear3]:\n",
    "        layer.parametrizations[\"weight\"][0].enabled = enabled"
   ],
   "id": "987aec199a803165",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:18:09.068604Z",
     "start_time": "2024-07-10T12:18:09.041517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "total_parameters_lora = 0\n",
    "total_parameters_non_lora = 0\n",
    "for index, layer in enumerate([net.linear1, net.linear2, net.linear3]):\n",
    "    total_parameters_lora += layer.parametrizations[\"weight\"][0].lora_A.nelement() + layer.parametrizations[\"weight\"][0].lora_B.nelement()\n",
    "    total_parameters_non_lora += layer.weight.nelement() + layer.bias.nelement()\n",
    "    print(\n",
    "        f'Layer {index+1}: W: {layer.weight.shape} + B: {layer.bias.shape} + Lora_A: {layer.parametrizations[\"weight\"][0].lora_A.shape} + Lora_B: {layer.parametrizations[\"weight\"][0].lora_B.shape}'\n",
    "    )\n",
    "# The non-LoRA parameters count must match the original network\n",
    "assert total_parameters_non_lora == total_parameters_original\n",
    "print(f'Total number of parameters (original): {total_parameters_non_lora:,}')\n",
    "print(f'Total number of parameters (original + LoRA): {total_parameters_lora + total_parameters_non_lora:,}')\n",
    "print(f'Parameters introduced by LoRA: {total_parameters_lora:,}')\n",
    "parameters_incremment = (total_parameters_lora / total_parameters_non_lora) * 100\n",
    "print(f'Parameters incremment: {parameters_incremment:.3f}%')"
   ],
   "id": "5c2159c5928e7eca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1: W: torch.Size([1000, 784]) + B: torch.Size([1000]) + Lora_A: torch.Size([1, 784]) + Lora_B: torch.Size([1000, 1])\n",
      "Layer 2: W: torch.Size([2000, 1000]) + B: torch.Size([2000]) + Lora_A: torch.Size([1, 1000]) + Lora_B: torch.Size([2000, 1])\n",
      "Layer 3: W: torch.Size([10, 2000]) + B: torch.Size([10]) + Lora_A: torch.Size([1, 2000]) + Lora_B: torch.Size([10, 1])\n",
      "Total number of parameters (original): 2,807,010\n",
      "Total number of parameters (original + LoRA): 2,813,804\n",
      "Parameters introduced by LoRA: 6,794\n",
      "Parameters incremment: 0.242%\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:18:09.253912Z",
     "start_time": "2024-07-10T12:18:09.249618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for name,param in net.named_parameters():\n",
    "    # print(name,param.shape)\n",
    "    # print(\"\\n\")\n",
    "    if 'lora' not in name:\n",
    "        print(f\"Freezing non-LoRA parameter {name}\")\n",
    "        param.requires_grad = False"
   ],
   "id": "cfde5df6fe37684",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing non-LoRA parameter linear1.bias\n",
      "Freezing non-LoRA parameter linear1.parametrizations.weight.original\n",
      "Freezing non-LoRA parameter linear2.bias\n",
      "Freezing non-LoRA parameter linear2.parametrizations.weight.original\n",
      "Freezing non-LoRA parameter linear3.bias\n",
      "Freezing non-LoRA parameter linear3.parametrizations.weight.original\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:18:13.498279Z",
     "start_time": "2024-07-10T12:18:09.906702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mnist_ds = datasets.MNIST(root='./data',train=True,download=True,transform=transform)\n",
    "\n",
    "exclude_indices = mnist_ds.targets == 9\n",
    "mnist_ds.data = mnist_ds.data[exclude_indices]\n",
    "mnist_ds.targets = mnist_ds.targets[exclude_indices]\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(mnist_ds,batch_size=10,shuffle=True)\n",
    "\n",
    "train(train_dl,net,epochs=1,total_iteration_limit=100)"
   ],
   "id": "557c340e90ef9478",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  99%|█████████▉| 99/100 [00:03<00:00, 28.07it/s, loss=2.38e-10]\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:18:37.738028Z",
     "start_time": "2024-07-10T12:18:37.676423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "assert torch.all(net.linear1.parametrizations.weight.original == original_weights['linear1.weight'])\n",
    "assert torch.all(net.linear2.parametrizations.weight.original == original_weights['linear2.weight'])\n",
    "assert torch.all(net.linear3.parametrizations.weight.original == original_weights['linear3.weight'])\n",
    "\n",
    "enable_disable_lore(enabled=True)\n",
    "\n",
    "assert torch.equal(net.linear1.weight,net.linear1.parametrizations.weight.original + (net.linear1.parametrizations.weight[0].lora_B @ net.linear1.parametrization.weight[0].lora_A))"
   ],
   "id": "d7d258398844ecc8",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ParametrizedLinear' object has no attribute 'parametrization'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[56], line 7\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mall(net\u001B[38;5;241m.\u001B[39mlinear3\u001B[38;5;241m.\u001B[39mparametrizations\u001B[38;5;241m.\u001B[39mweight\u001B[38;5;241m.\u001B[39moriginal \u001B[38;5;241m==\u001B[39m original_weights[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlinear3.weight\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m      5\u001B[0m enable_disable_lore(enabled\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m----> 7\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mequal(net\u001B[38;5;241m.\u001B[39mlinear1\u001B[38;5;241m.\u001B[39mweight,net\u001B[38;5;241m.\u001B[39mlinear1\u001B[38;5;241m.\u001B[39mparametrizations\u001B[38;5;241m.\u001B[39mweight\u001B[38;5;241m.\u001B[39moriginal \u001B[38;5;241m+\u001B[39m (net\u001B[38;5;241m.\u001B[39mlinear1\u001B[38;5;241m.\u001B[39mparametrizations\u001B[38;5;241m.\u001B[39mweight[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mlora_B \u001B[38;5;241m@\u001B[39m net\u001B[38;5;241m.\u001B[39mlinear1\u001B[38;5;241m.\u001B[39mparametrization\u001B[38;5;241m.\u001B[39mweight[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mlora_A))\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1709\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   1707\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m modules:\n\u001B[0;32m   1708\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[1;32m-> 1709\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'ParametrizedLinear' object has no attribute 'parametrization'"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:19:28.277477Z",
     "start_time": "2024-07-10T12:19:15.866036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "enable_disable_lore(True)\n",
    "test()"
   ],
   "id": "5ba6ea078844c797",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 1000/1000 [00:12<00:00, 80.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.227\n",
      "wrong counts for the digit 0 : 694\n",
      "wrong counts for the digit 1 : 1135\n",
      "wrong counts for the digit 2 : 692\n",
      "wrong counts for the digit 3 : 1010\n",
      "wrong counts for the digit 4 : 982\n",
      "wrong counts for the digit 5 : 889\n",
      "wrong counts for the digit 6 : 346\n",
      "wrong counts for the digit 7 : 1010\n",
      "wrong counts for the digit 8 : 974\n",
      "wrong counts for the digit 9 : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:19:40.962333Z",
     "start_time": "2024-07-10T12:19:28.290103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "enable_disable_lore(False)\n",
    "test()"
   ],
   "id": "c2d363b07bf0913e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 1000/1000 [00:12<00:00, 78.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.854\n",
      "wrong counts for the digit 0 : 208\n",
      "wrong counts for the digit 1 : 27\n",
      "wrong counts for the digit 2 : 150\n",
      "wrong counts for the digit 3 : 135\n",
      "wrong counts for the digit 4 : 223\n",
      "wrong counts for the digit 5 : 167\n",
      "wrong counts for the digit 6 : 139\n",
      "wrong counts for the digit 7 : 73\n",
      "wrong counts for the digit 8 : 132\n",
      "wrong counts for the digit 9 : 204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c7ceaa1517c1b6bd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
